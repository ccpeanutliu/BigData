{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "nlp = StanfordCoreNLP(r'/home/cior5757e/ray/stanford-corenlp-full-2018-10-05', lang='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(list): \n",
    "    pattern = '[0-9]'\n",
    "    list = [re.sub(pattern, '', i) for i in list] \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('label_news.csv')[['title', 'content']]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_words = []\n",
    "with open('./stock.txt','r') as f:\n",
    "    for i in f.readlines():\n",
    "        i = i.strip()\n",
    "        stock_words.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for obj in range(data.shape[0]):\n",
    "    #label.append([])\n",
    "    try:\n",
    "        b = 0\n",
    "        for i in stock_words:\n",
    "            if data[obj][1].find(i) != -1:\n",
    "                b = 1\n",
    "                break\n",
    "        if b:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(0)\n",
    "    except:\n",
    "        b = 0\n",
    "        for i in stock_words:\n",
    "            if data[obj][0].find(i) != -1:\n",
    "                b = 1\n",
    "                break\n",
    "        if b:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(0)\n",
    "\n",
    "label = np.array(label) # associate to stock or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247273, 3)\n",
      "138276\n"
     ]
    }
   ],
   "source": [
    "label = label.reshape(label.shape[0], 1)\n",
    "data = np.hstack([data,label])\n",
    "print(data.shape)\n",
    "print(sum(data[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138276, 2)\n"
     ]
    }
   ],
   "source": [
    "# delete not stocking data\n",
    "del_row = []\n",
    "for i in range(data.shape[0]):\n",
    "    if data[i][2] == 0:\n",
    "        del_row.append(i)\n",
    "del_row = np.array(del_row)\n",
    "np.save('del_row.npy', del_row)\n",
    "data = np.delete(data, del_row, 0)\n",
    "data = np.delete(data, 2, 1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247273, 3)\n",
      "(138276, 3)\n",
      "(125058, 2)\n",
      "(125058, 3)\n"
     ]
    }
   ],
   "source": [
    "#del_row = np.load('delete_rows.npy', allow_pickle = True)\n",
    "y = pd.read_csv('label_news.csv')[['label_3','label_5','label_10']]\n",
    "y = np.array(y)\n",
    "print(y.shape)\n",
    "y = np.delete(y, del_row, axis=0)\n",
    "print(y.shape)\n",
    "del_row = []\n",
    "for i in range(y.shape[0]):\n",
    "    if y[i][0] == -1 and y[i][1] == -1 and y[i][2] == -1:\n",
    "        del_row.append(i)\n",
    "\n",
    "del_row = np.array(del_row)\n",
    "np.save('del_nodata.npy', del_row)\n",
    "y = np.delete(y, del_row, axis=0)\n",
    "data = np.delete(data, del_row, axis=0)\n",
    "print(data.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    try:\n",
    "        data[i] = remove(data[i])\n",
    "    except:\n",
    "        data[i][0] = re.sub('[0-9]', '', data[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark = [\"，\",\"。\",\"！\",\"？\",\"?\",\"!\",\".\",\"、\",\"）\",\"（\",\"(\",\")\",\" \",\"「\",\"」\",\"『\",\"』\",\"【\",\"】\",\",\",\n",
    "         '1','2','3','4','5','6','7','8','9','0',\" \", \"<BR>\", \"<\", \">\", \".\", \"：\",\":\"]\n",
    "nums = ['1','2','3','4','5','6','7','8','9','0']\n",
    "stop_words = []\n",
    "with open('./stop_words.txt','r') as f:\n",
    "    for i in f.readlines():\n",
    "        i = i.strip()\n",
    "        stop_words.append(i)\n",
    "stop_words += mark\n",
    "stop_words = np.array(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125058\n",
      "0 0.0003712177276611328\n",
      "10000 355.3376576900482\n",
      "20000 364.372211933136\n",
      "30000 349.15840792655945\n",
      "40000 337.12468457221985\n",
      "50000 338.06488370895386\n",
      "60000 291.32777404785156\n",
      "70000 286.1272768974304\n",
      "80000 293.25032329559326\n",
      "90000 304.4039466381073\n",
      "100000 298.9900288581848\n",
      "110000 304.0956914424896\n",
      "120000 307.8253107070923\n"
     ]
    }
   ],
   "source": [
    "# 切詞會跑很久，這邊就不執行了\n",
    "content = []\n",
    "print(data.shape[0])\n",
    "s = time.time()       \n",
    "for i in range(data.shape[0]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i, time.time()-s)\n",
    "        s = time.time()\n",
    "    try:\n",
    "        segments = nlp.word_tokenize(data[i][1])\n",
    "        tmp = list(filter(lambda a: a not in stop_words and a != '\\n', segments))\n",
    "        content.append(tmp)\n",
    "    except:\n",
    "        segments = nlp.word_tokenize(data[i][0])\n",
    "        tmp = list(filter(lambda a: a not in stop_words and a != '\\n', segments))\n",
    "        content.append(tmp)\n",
    "content = np.array(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125058, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month = np.load('month.npy', allow_pickle = True)\n",
    "month = month.reshape(month.shape[0],1)\n",
    "content = content.reshape(content.shape[0],1)\n",
    "content = np.hstack([content,month])\n",
    "content = np.hstack([content,y])\n",
    "content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train.npy',content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
